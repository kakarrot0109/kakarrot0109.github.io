<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="KAKARROT">


    <meta name="subtitle" content="Heaven helps those who help themselves.">


    <meta name="description" content="I just want things to be what they are supposed to be.">


    <meta name="keywords" content="产品,哲学,历史,魔兽,音乐">


<title>AI Agent学习(二) | KAKARROT&#39;S BLOG</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 7.3.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Kakarrot&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Kakarrot&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">展开全部</a>
        <a onclick="go_top()">回到顶部</a>
        <a onclick="go_bottom()">回到底部</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? '展开全部' : '收起全部';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>

    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">AI Agent学习(二)</h1>
            
        </header>

        <div class="post-content">
            <p>家中台式机性能还可以，能运行个本地小模型，正好用于实战，搜搜攻略开搞。</p>
<h2 id="本地部署LLM语言大模型"><a href="#本地部署LLM语言大模型" class="headerlink" title="本地部署LLM语言大模型"></a>本地部署LLM语言大模型</h2><h3 id="Step1：下载安装Ollama"><a href="#Step1：下载安装Ollama" class="headerlink" title="Step1：下载安装Ollama"></a>Step1：下载安装Ollama</h3><p>打开浏览器，访问 Ollama官网：<a target="_blank" rel="noopener" href="https://ollama.com/">https://ollama.com/</a></p>
<p>点击大大的 “Download” 按钮，然后选择 “Download for Windows”。</p>
<p>下载后，双击安装程序，一路点击”Next”即可。安装程序会自动处理环境变量等配置。</p>
<p>安装完成后，Ollama会在后台作为一个服务运行（你可以在任务栏右下角看到一个小小的羊驼图标）。</p>
<h3 id="Step2：验证安装并拉取模型"><a href="#Step2：验证安装并拉取模型" class="headerlink" title="Step2：验证安装并拉取模型"></a>Step2：验证安装并拉取模型</h3><p>打开Windows的“终端”或“命令提示符(CMD)”。</p>
<p>输入以下命令并回车：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama --version</span><br></pre></td></tr></table></figure>

<p>如果安装成功，它会显示Ollama的版本号。</p>
<p><strong>选择并拉取你的第一个模型。</strong> 我为你精选了3个不同特色的模型，让你感受一下：</p>
<ul>
<li><p><strong>通用全能王 (主力模型): <code>llama3:8b</code></strong></p>
<ul>
<li><p>Meta最新发布的模型，综合能力极强，代码能力和英文对话能力顶尖。是目前8B尺寸的王者。</p>
</li>
<li><p>在终端输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull llama3:8b</span><br></pre></td></tr></table></figure>
</li>
<li><p>你会看到它开始下载模型文件（大约4.7GB）。请耐心等待。</p>
</li>
</ul>
</li>
<li><p><strong>中文小钢炮: <code>qwen2:7b</code></strong></p>
<ul>
<li><p>阿里巴巴通义千问的最新开源模型，对中文的理解和生成能力非常出色。</p>
</li>
<li><p>在终端输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull qwen2:7b</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>多模态新星（能看图）: <code>llava:latest</code></strong></p>
<ul>
<li><p>这是一个多模态模型，不仅能对话，还能“看懂”图片的内容。</p>
</li>
<li><p>在终端输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull llava</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="Step3：运行并与本地LLM对话"><a href="#Step3：运行并与本地LLM对话" class="headerlink" title="Step3：运行并与本地LLM对话"></a>Step3：运行并与本地LLM对话</h3><ol>
<li><p>拉取完成后，我们先来运行<code>llama3:8b</code>。在终端输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run llama3:8b</span><br></pre></td></tr></table></figure>
</li>
<li><p>稍等片刻，当看到 <code>&gt;&gt;&gt; Send a message (/? for help)</code> 的提示时，恭喜你！你的本地AI大脑已经启动并等着你提问了。</p>
</li>
<li><p>现在，直接输入你的问题，例如： <code>你是谁？</code></p>
</li>
<li><p>按回车，模型会开始一个词一个词地生成答案。你会直观地感受到它在你自己的电脑上“思考”的过程。</p>
</li>
<li><p>要退出对话，可以输入 <code>/bye</code>。要尝试其他模型，比如<code>qwen2:7b</code>，只需再次运行 <code>ollama run qwen2:7b</code>。</p>
</li>
</ol>
<h3 id="Step4：验证GPU是否在工作"><a href="#Step4：验证GPU是否在工作" class="headerlink" title="Step4：验证GPU是否在工作"></a>Step4：验证GPU是否在工作</h3><p>这是确保你获得最佳性能的关键一步。</p>
<ol>
<li>在与模型对话时（当它正在快速生成文本时），按下 <code>Ctrl + Shift + Esc</code> 打开Windows的“任务管理器”。</li>
<li>点击左侧的“性能”选项卡。</li>
<li>在左侧列表中，找到你的 <strong>NVIDIA GeForce RTX 4070 SUPER</strong> 并点击它。</li>
<li>观察右侧的图表。你应该能看到 <strong>“3D”</strong> 或 <strong>“Cuda”</strong> 图表有明显的活动（利用率飙升），并且 <strong>“专用GPU内存”</strong> 使用量会显著上升（对于8B模型，大约会占用5-6GB）。</li>
</ol>
<p><strong>如果能看到GPU活动，那就完美了！</strong> 这意味着Ollama已经成功调用了你的显卡进行加速，你正在享受“满血”的本地LLM性能。如果GPU没有活动，通常是因为NVIDIA驱动程序问题，请确保更新到最新版Game Ready或Studio驱动。</p>

        </div>

        
                <section class="post-nav">
            
                <a class="prev" rel="prev" href="/posts/53c2bc53/">AI Agent学习(三)</a>
            
            
            <a class="next" rel="next" href="/posts/8200071a/">AI Agent学习(一)</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© KAKARROT | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>